{
    "capabilities":  [
                         "analysis",
                         "processing",
                         "automation"
                     ],
    "version":  "1.0.0",
    "category":  "ai-research",
    "name":  "tokenization-sentencepiece",
    "description":  "Skill template for tokenization-sentencepiece",
    "language":  "python",
    "requirements":  {
                         "dependencies":  [
                                              "requests",
                                              "json",
                                              "logging"
                                          ],
                         "pythonVersion":  "\u003e=3.8"
                     },
    "settings":  {
                     "maxRetries":  3,
                     "timeout":  300,
                     "enabled":  true
                 }
}
