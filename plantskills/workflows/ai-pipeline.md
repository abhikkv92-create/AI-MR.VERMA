---
description: Advanced AI/ML orchestration with LangChain, memory systems, and MCP integration.
---

# /ai-pipeline - Advanced AI Orchestration Engine

$ARGUMENTS: [ai_task_description]

## ü§ñ Applied Agents: `ai-researcher`, `backend-specialist`

This workflow builds sophisticated AI systems including LLM chains, memory architectures, and tool integrations.

## üõ†Ô∏è Skills Activated
- **LLM Frameworks:** `langchain-architecture`, `ai-sdk`
- **Memory Systems:** `conversation-memory`, `agent-memory-systems`, `agent-memory`
- **Integration:** `mcp-builder`, `python-sdk`, `javascript-sdk`
- **Optimization:** `gemini-token-optimization`, `token-efficiency`

## üìã Step-by-Step Execution

1.  **Architecture Design**
    - Agent: `ai-researcher`
    - Action: Select LLM framework (LangChain vs AI SDK vs custom).
    - Decision: Memory type (short-term, long-term, entity-based).

2.  **Memory System Setup**
    - Skill: `conversation-memory` or `agent-memory-systems`
    - Action: Configure vector stores, embedding strategies.
    - Pattern: RAG pipeline if knowledge retrieval needed.

3.  **Tool/MCP Integration**
    - Skill: `mcp-builder`
    - Action: Create MCP servers for external service access.
    - SDKs: Use `python-sdk` or `javascript-sdk` for client integration.

4.  **Token Optimization**
    - Skill: `gemini-token-optimization`, `token-efficiency`
    - Action: Minimize costs via caching, batch queries, model selection.

5.  **Testing & Validation**
    - Action: Verify latency, accuracy, and cost per query.

---

## üö¶ Output Format
Produces AI system architecture, code scaffolding, and integration guides.

## Examples
```
/ai-pipeline conversational agent with memory
/ai-pipeline RAG system for documentation
/ai-pipeline MCP server for GitHub integration
/ai-pipeline LangChain agent with tools
```
