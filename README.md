<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                      â•‘
â•‘   â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•‘
â•‘   â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•‘
â•‘   â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—     â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•‘
â•‘   â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘      â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•‘
â•‘   â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•       â•šâ•â•â•â•  â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•  â•šâ•â•â•‘
â•‘                                                                      â•‘
â•‘              ğŸ¤– UNIFIED AI INTELLIGENCE PLATFORM ğŸ¤–                 â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white)](docker/docker-compose.yml)
[![NVIDIA](https://img.shields.io/badge/NVIDIA-Kimi_K2.5-76B900?style=for-the-badge&logo=nvidia&logoColor=white)](https://build.nvidia.com)
[![Status](https://img.shields.io/badge/Status-Production-00C853?style=for-the-badge)]()

**ğŸš€ Your Personal AI Assistant | Multi-Agent System | Autonomous Operation**

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Documentation](docs/) â€¢ [Docker](#-docker-deployment)

</div>

---

## ğŸ“Š Project Overview

```mermaid
graph TB
    subgraph "ğŸ§  MR.VERMA AI System"
        A[ğŸ® Unified Interface] --> B[ğŸ¤– Agent Orchestrator]
        B --> C1[ğŸ’¬ Chat Agent]
        B --> C2[ğŸ“ Code Agent]
        B --> C3[ğŸ” Analysis Agent]
        B --> C4[ğŸ¨ Design Agent]
        B --> C5[ğŸ”’ Security Agent]
    end
    
    subgraph "âš¡ AI Engines"
        D1[NVIDIA Kimi K2.5]
        D2[Secondary Engine]
        D3[Vision Engine]
    end
    
    subgraph "ğŸ’¾ Memory & Storage"
        E1[(Milvus Vector DB)]
        E2[ğŸ—‚ï¸ File System]
        E3[â˜ï¸ Cloud APIs]
    end
    
    C1 --> D1
    C2 --> D1
    C3 --> D2
    C4 --> D3
    B --> E1
    B --> E2
    B --> E3
```

**MR.VERMA** is a production-ready, multi-modal AI platform that combines:
- ğŸ¯ **27+ Specialized AI Agents** for different tasks
- ğŸ§  **Multiple AI Engines** (NVIDIA Kimi K2.5, Vision, Secondary)
- ğŸ’¾ **Vector Memory** with Milvus integration
- ğŸ³ **Docker Support** for easy deployment
- âš¡ **Autonomous Operation** - runs without user intervention

---

## ğŸš€ Quick Start

### ğŸªŸ Windows
```powershell
# One-click start
start.bat

# Or with specific mode
start.bat enhanced    # Full agent system
start.bat ultimate    # With prompt library
```

### ğŸ§ Linux/Mac
```bash
# Make executable and run
chmod +x start.sh
./start.sh

# Or specific mode
./start.sh enhanced
./start.sh ultimate
```

### ğŸ³ Docker (Recommended for Production)
```bash
# Start everything in detached mode
docker-compose -f docker/docker-compose.yml up -d

# Check status
docker-compose -f docker/docker-compose.yml ps

# View logs
docker-compose -f docker/docker-compose.yml logs -f
```

---

## âœ¨ Features

### ğŸ¯ Core Capabilities

| Feature | Description | Status |
|---------|-------------|--------|
| ğŸ’¬ **AI Chat** | Natural conversations with context memory | âœ… Ready |
| ğŸ“ **Code Generation** | Python, JavaScript, Java, C++, and more | âœ… Ready |
| ğŸ” **Code Analysis** | Bug detection, optimization, refactoring | âœ… Ready |
| ğŸ¨ **UI/UX Design** | Interface mockups and design systems | âœ… Ready |
| ğŸ”’ **Security Scan** | Vulnerability detection and fixes | âœ… Ready |
| ğŸ“Š **Data Processing** | CSV, JSON, database analysis | âœ… Ready |
| ğŸŒ **Web Scraping** | Extract data from websites | âœ… Ready |
| ğŸ§ª **Testing** | Unit test generation and execution | âœ… Ready |

### ğŸ¤– Agent System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¤– AGENT ECOSYSTEM                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ¯ Core Agents                    ğŸ› ï¸ Specialized Agents    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚  â€¢ Orchestrator                    â€¢ Frontend Specialist    â”‚
â”‚  â€¢ Project Planner                 â€¢ Backend Engineer       â”‚
â”‚  â€¢ Explorer Agent                  â€¢ Security Architect     â”‚
â”‚  â€¢ Research Analyst                â€¢ DevOps Engineer        â”‚
â”‚                                     â€¢ Performance Optimizer â”‚
â”‚                                                              â”‚
â”‚  ğŸ“š Total: 27+ Agents | 66+ Skills | 19 Workflows          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§  Memory System

```mermaid
graph LR
    A[User Input] --> B[Embedding Service]
    B --> C{Vector Store}
    C -->|Milvus Available| D[(Milvus DB)]
    C -->|Fallback| E[FAISS]
    C -->|Last Resort| F[In-Memory]
    D --> G[Context Retrieval]
    E --> G
    F --> G
    G --> H[AI Response]
```

---

## ğŸ—ï¸ Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRESENTATION LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   CLI    â”‚  â”‚   API    â”‚  â”‚ Terminal â”‚  â”‚  Docker  â”‚          â”‚
â”‚  â”‚  start   â”‚  â”‚  Server  â”‚  â”‚   Chat   â”‚  â”‚  Compose â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ORCHESTRATION LAYER                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚  SupremeOrchestrator                          â”‚
â”‚                    â”‚  â€¢ Task Routing  â”‚                           â”‚
â”‚                    â”‚  â€¢ Agent Selectionâ”‚                          â”‚
â”‚                    â”‚  â€¢ Context Managementâ”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  AI LAYER    â”‚  â”‚    AGENT LAYER      â”‚  â”‚  MEMORY    â”‚
â”‚              â”‚  â”‚                     â”‚  â”‚            â”‚
â”‚ â€¢ Primary    â”‚  â”‚ â€¢ Frontend Cluster  â”‚  â”‚ â€¢ Milvus   â”‚
â”‚ â€¢ Secondary  â”‚  â”‚ â€¢ Intelligence      â”‚  â”‚ â€¢ FAISS    â”‚
â”‚ â€¢ Vision     â”‚  â”‚ â€¢ Platform          â”‚  â”‚ â€¢ Chroma   â”‚
â”‚ â€¢ Embeddings â”‚  â”‚ â€¢ Security          â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

<div align="center">

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Core** | Python 3.9+ | Main runtime |
| **AI API** | NVIDIA NIM | Kimi K2.5 inference |
| **Vector DB** | Milvus | Semantic memory |
| **Web Framework** | Flask | API endpoints |
| **Container** | Docker | Deployment |
| **Embeddings** | sentence-transformers | Vector generation |
| **UI** | Rich + Prompt Toolkit | Terminal interface |

</div>

---

## ğŸ“¦ Installation

### Prerequisites

- âœ… Python 3.9 or higher
- âœ… NVIDIA API Key (free tier available)
- âœ… Docker (optional, for containerized deployment)

### Step-by-Step Setup

```bash
# 1. Clone the repository
git clone https://github.com/abhikkv92-create/AI-MR.VERMA.git
cd AI-MR.VERMA

# 2. Create virtual environment (recommended)
python -m venv venv

# Windows:
venv\Scripts\activate

# Linux/Mac:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.unified.txt

# 4. Set up your API key
# The system will prompt you on first run, or create .env file:
echo "NVIDIA_API_KEY=your_api_key_here" > .env

# 5. Start MR.VERMA
python unified/mrverma.py
```

---

## ğŸ³ Docker Deployment

### Quick Docker Start

```bash
# Build and start all services
docker-compose -f docker/docker-compose.yml up -d

# Services will be available at:
# â€¢ Collector API: http://localhost:8550
# â€¢ Milvus: localhost:19530
# â€¢ MinIO: http://localhost:9001
```

### Docker Services

```mermaid
graph TB
    subgraph "Docker Compose Stack"
        A[ğŸ¯ Collector Service<br/>Port: 8550] 
        B[ğŸ“ Trainer Service<br/>Auto-training]
        C[(ğŸ—„ï¸ Milvus<br/>Vector DB)]
        D[(â˜ï¸ MinIO<br/>Object Store)]
        E[(ğŸ”§ etcd<br/>Metadata)]
    end
    
    A --> C
    A --> D
    C --> E
    B --> C
    B --> D
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `NVIDIA_API_KEY` | - | Your NVIDIA API key |
| `NVIDIA_MODEL` | moonshotai/kimi-k2.5 | AI model to use |
| `MILVUS_HOST` | milvus-standalone | Milvus server host |
| `COLLECTOR_PORT` | 8550 | API server port |
| `LOG_LEVEL` | INFO | Logging verbosity |

---

## ğŸ® Usage Examples

### ğŸ’¬ Chat Mode
```python
# Start interactive chat
python unified/mrverma.py

# Or use API directly
curl -X POST http://localhost:8550/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "moonshotai/kimi-k2.5",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

### ğŸ“ Code Generation
```
You: Generate a Python function to calculate prime numbers

MR.VERMA: 
def is_prime(n):
    if n < 2:
        return False
    for i in range(2, int(n**0.5) + 1):
        if n % i == 0:
            return False
    return True
```

### ğŸ”’ Security Scan
```python
# Analyze code for vulnerabilities
from core.security_orchestrator import SecurityOrchestrator

scanner = SecurityOrchestrator()
results = scanner.scan_code("your_code.py")
print(f"Found {len(results.vulnerabilities)} issues")
```

---

## ğŸ“Š Performance & Stats

<div align="center">

| Metric | Value |
|--------|-------|
| ğŸš€ **Response Time** | < 2s average |
| ğŸ’¾ **Memory Usage** | ~512MB base |
| ğŸ¯ **Accuracy** | 95%+ (contextual) |
| ğŸ”„ **Concurrent Users** | 100+ (Docker mode) |
| ğŸ“¦ **Repository Size** | ~47MB (after cleanup) |

</div>

---

## ğŸ› ï¸ Development

### Project Structure

```
AI-MR.VERMA/
â”œâ”€â”€ ğŸ¯ unified/           # Main entry points
â”‚   â”œâ”€â”€ mrverma.py       # Primary interface
â”‚   â”œâ”€â”€ mrverma_enhanced.py
â”‚   â””â”€â”€ mrverma_ultimate.py
â”œâ”€â”€ ğŸ§  core/             # Core AI engines
â”‚   â”œâ”€â”€ orchestrator.py  # Main orchestrator
â”‚   â”œâ”€â”€ ai/              # AI engines
â”‚   â””â”€â”€ memory_service.py
â”œâ”€â”€ ğŸ¤– agents/           # Agent definitions
â”œâ”€â”€ ğŸ³ docker/           # Docker configuration
â”œâ”€â”€ ğŸ“š docs/             # Documentation
â”œâ”€â”€ ğŸ§ª tests/            # Test suite
â””â”€â”€ ğŸ”Œ plugins/          # Plugin system
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=core --cov=agents

# Run specific test file
pytest tests/test_basic.py
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Quick Contribution Steps

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’» Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ”„ Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- ğŸ¤– Powered by [NVIDIA NIM](https://build.nvidia.com) and Kimi K2.5
- ğŸ’¾ Vector storage by [Milvus](https://milvus.io)
- ğŸ³ Container orchestration with [Docker](https://docker.com)
- ğŸ¨ UI components from [Rich](https://github.com/Textualize/rich)

---

## ğŸ“ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/abhikkv92-create/AI-MR.VERMA/issues)
- ğŸ“§ **Email**: Contact through GitHub
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/abhikkv92-create/AI-MR.VERMA/discussions)

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ by the MR.VERMA Team

*Version: 6.0 Unified | Last Updated: 2026-02-19*

</div>
